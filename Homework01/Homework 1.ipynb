{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Task-1.-Compiling-Ebola-Data\"><span class=\"toc-item-num\">Task 1.&nbsp;&nbsp;</span>Compiling Ebola Data</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-2.-RNA-Sequences\"><span class=\"toc-item-num\">Task 2.&nbsp;&nbsp;</span>RNA Sequences</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-3.-Class-War-in-Titanic\"><span class=\"toc-item-num\">Task 3.&nbsp;&nbsp;</span>Class War in Titanic</a></div></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data' # Use the data folder provided in Tutorial 02 - Intro to Pandas.\n",
    "EBOLA = DATA_FOLDER + \"/ebola\"\n",
    "GUINEA = EBOLA + \"/guinea_data\"\n",
    "LIBERIA = EBOLA + \"/liberia_data\"\n",
    "SIERRA_LEONE = EBOLA + \"/sl_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Compiling Ebola Data\n",
    "\n",
    "The `DATA_FOLDER/ebola` folder contains summarized reports of Ebola cases from three countries (Guinea, Liberia and Sierra Leone) during the recent outbreak of the disease in West Africa. For each country, there are daily reports that contain various information about the outbreak in several cities in each country.\n",
    "\n",
    "Use pandas to import these data files into a single `Dataframe`.\n",
    "Using this `DataFrame`, calculate for *each country*, the *daily average* per year of *new cases* and *deaths*.\n",
    "Make sure you handle all the different expressions for *new cases* and *deaths* that are used in the reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sierra_descriptions = set([b for a,b,c, in list(preprocessed_sierra.index.values)])\n",
    "print(\"Sierra: {}\\n\".format(sierra_descriptions))\n",
    "\n",
    "guinea_descriptions = set([b for a,b,c, in list(preprocessed_guinea.index.values)])\n",
    "print(\"Guinea: {}\\n\".format(guinea_descriptions))\n",
    "\n",
    "liberia_descriptions = set([b for a,b,c, in list(preprocessed_liberia.index.values)])\n",
    "print(\"Liberia: {}\\n\".format(liberia_descriptions))\n",
    "#sierra[~sierra['34 Military Hospital'].isnull()]\n",
    "#preprocessed_sierra.iloc[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Importing the data\n",
    "\n",
    "First of all, we will split the cleaning in three parts, one for each country, since the files were consistent for each country. Hence, we start by loading all of the data from each folder into three different DataFrames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# A few helper functions\n",
    "\n",
    "\"\"\"\n",
    "Returns a pandas dataframe from a folder full of \n",
    "csv files.\n",
    "\"\"\"\n",
    "def create_folder_data_frame(FOLDER):\n",
    "    list_ = []\n",
    "    for file_ in glob.glob(FOLDER + \"/*.csv\"):\n",
    "        df = pd.read_csv(file_, index_col=None)\n",
    "        list_.append(df)\n",
    "    return pd.concat(list_)\n",
    "\n",
    "\"\"\"\n",
    "Sets a new column \"Country\" that becomes part of a multi index\n",
    "afterwards, and returns the indexed frame.\n",
    "\"\"\"\n",
    "def index_and_country(data_frame, country):\n",
    "    data_frame[\"Country\"] = country\n",
    "    data_frame.set_index(['Date', 'Description', 'Country'], inplace=True)\n",
    "    return data_frame\n",
    "    \n",
    "\"\"\"\n",
    "We preprocess each Country one after the other and set their indices\n",
    "to a MultiIndex of Date, Description and Country, with each column\n",
    "mapped to one of these indices.\n",
    "\"\"\"\n",
    "def preprocess(FOLDER, name, columns=None):\n",
    "    frame = create_folder_data_frame(FOLDER)\n",
    "    if columns:\n",
    "        frame.rename(columns=columns, inplace=True)\n",
    "    frame.Date = pd.to_datetime(frame.Date)\n",
    "    frame = index_and_country(frame, name)\n",
    "    return frame\n",
    "    \n",
    "preprocessed_guinea = preprocess(GUINEA, \"Guinea\")\n",
    "\n",
    "liberia_column_mapping = {\"Variable\": \"Description\", \"National\": \"Totals\", 'Unnamed: 18': \"Unknown\"}\n",
    "preprocessed_liberia = preprocess(LIBERIA, \"Liberia\", liberia_column_mapping)\n",
    "\n",
    "sierra_column_mapping = {\"variable\": \"Description\", \"National\": \"Totals\", 'Unnamed: 18': \"Unknown\", \"date\": \"Date\"}\n",
    "preprocessed_sierra = preprocess(SIERRA_LEONE, \"Sierra Leone\", sierra_column_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Cleaning up\n",
    "\n",
    "Now that we have our three DataFrames, we need to merge them into a single one in order to query it to get the daily average deaths and cases. What we need to do in order to merge them, is to clean each DataFrame, and create a consistency inbetween columns after choosing which columns to use.\n",
    "\n",
    "After taking a look at the data, we decided to deliver the daily average of new cases and new deaths as a sum of the following categories: the suspected, probables, and confirmed cases and deaths, hence we only kept for each DataFrame the right columns. When the \"right\" columns are not perfectly defined, we explain which one we chose and why. The following set of columns are preselected after looking at the data, the other columns were either inconsistent or made no sense whatsoever.\n",
    "\n",
    "#### 1.2.1 Guinea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The columns that are of interest to us, mapped\n",
    "# to their centralized names for the final DataFrame\n",
    "interest = { 'New cases of suspects': 'new_suspected',\n",
    "        'New cases of probables': 'new_probable',\n",
    "        'New cases of confirmed': 'new_confirmed',\n",
    "        'Total deaths (confirmed + probables + suspects)': 'deaths',\n",
    "        'Total deaths of suspects': 'death_suspected',\n",
    "        'Total deaths of probables': 'death_probable',\n",
    "        'Total deaths of confirmed': 'death_confirmed' }\n",
    "\n",
    "    \n",
    "# We start by keeping only the interesting columns for the task\n",
    "interest_indices = preprocessed_guinea.index.get_level_values('Description').isin(interest.keys())\n",
    "guinea_df = preprocessed_guinea[interest_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now here is the first assumption we made regarding the data of Guinea, there are no missing values in the totals of deaths, but there are some NaN values in the New cases. We figured that of these new cases, NaN meant that there were either no data for the day, or that the data was not entered. It seems more plausible that people did not fill the data when there was no new cases, so we went with that explanation and changed all NaN values to 0. Also, since the number of cases and deaths can only be discrete we converted the dataframe to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guinea_df = guinea_df.fillna(0).astype(int)\n",
    "guinea_df = guinea_df.sort_index(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By verifying that the sum of cities and the total column are the same, we can see that there are some discrepencies. We then decided to remove the rows where the discrepencies are too high, namely 10% compared to the Totals column. Otherwise we keep the row, and we finally decided to keep mean of both columns, as they were quite similar, and it was impossible to split them apart and choose one. So the mean is the most obvious merging tool. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Keeping only the interesting columns, namely one for the Total\n",
    "# and one for the total of cities, to filter out unreliable data points\n",
    "guinea_df['Cities_total'] = guinea_df.sum(1) - guinea_df.Totals\n",
    "guinea_df = guinea_df[['Cities_total', 'Totals']]\n",
    "equality = sum(guinea_df['Cities_total'] == guinea_df['Totals']) == 0\n",
    "print(\"Does the sum of cities equal the Totals columm ? {}\".format(equality))\n",
    "\n",
    "# Now we want to remove the rows for which the total of cities \n",
    "# diverges from the Totals column of at least 10%\n",
    "guinea_df = guinea_df[np.abs(guinea_df.Cities_total - guinea_df.Totals) <= (0.1 * guinea_df.Totals)]\n",
    "guinea_df['Totals'] = guinea_df.mean(1)\n",
    "guinea_df = guinea_df.Totals\n",
    "\n",
    "# Converting the indices to columns, and readjusting the indices\n",
    "guinea_df = guinea_df.unstack('Description', fill_value=0)\n",
    "guinea_df.rename(columns=interest, inplace=True)\n",
    "\n",
    "display(HTML(guinea_df.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the total deaths, we can see that there is a row where we have missing data, we assumed here that the person forgot to write the measurements, hence we decided to fill the row with the mean of the previous and next measurements. That would simulate a linear increase and seems reasonable for one data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the row with the mean of the previous and next measurements\n",
    "# We also remove the cumulative sum, in order to get the daily data\n",
    "for c in guinea_df.columns:\n",
    "    if \"death_\" in c:\n",
    "        guinea_df[c].loc[('2014-09-26', 'Guinea')] = int((guinea_df[c].loc[('2014-09-24', 'Guinea')] + guinea_df[c].loc[('2014-09-30', 'Guinea')]) / 2)\n",
    "        guinea_df[c] = guinea_df[c] - guinea_df[c][0]\n",
    "        guinea_df[c][1:] = guinea_df[c][1:].copy().as_matrix() - guinea_df[c][:-1].copy().as_matrix()\n",
    "        \n",
    "# And finally, since the data can get negative because of the previous\n",
    "# computations we made, we can set them back to 0\n",
    "guinea_df[guinea_df < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can take a look at the sum of all 3 categories into one. But first, we need to choose how to process the fact that we can pick either from the deaths column or the sum of the three other categories of deaths. Let's take a look at the difference between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "guinea_df['new_cases'] = guinea_df[['new_suspected', 'new_confirmed', 'new_probable']].sum(axis=1)\n",
    "guinea_df['deaths_summed'] = guinea_df[['death_confirmed', 'death_probable', 'death_suspected']].sum(axis=1)\n",
    "# We reverse the cumulative sum on the deaths column to get a daily value\n",
    "guinea_df['deaths'] = guinea_df['deaths'] - guinea_df['deaths'][0]\n",
    "guinea_df['deaths'][1:] = guinea_df['deaths'][1:].copy().as_matrix() - guinea_df['deaths'][:-1].copy().as_matrix()\n",
    "\n",
    "display(HTML(guinea_df[['deaths', 'deaths_summed']].to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at the column deaths and the column death_summed, we can clearly see that they are about the same, besides a few discrepencies and two or three clearly wrong values. Hence, we decided to only retain the deaths_summed column that seemed more consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We now have a clean DataFrame to work with:\n",
    "guinea_df = guinea_df[['new_cases', 'deaths_summed']]\n",
    "guinea_df.rename(columns={'deaths_summed':'deaths'}, inplace=True)\n",
    "\n",
    "display(HTML(guinea_df.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Sierra Leone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. RNA Sequences\n",
    "\n",
    "In the `DATA_FOLDER/microbiome` subdirectory, there are 9 spreadsheets of microbiome data that was acquired from high-throughput RNA sequencing procedures, along with a 10<sup>th</sup> file that describes the content of each. \n",
    "\n",
    "Use pandas to import the first 9 spreadsheets into a single `DataFrame`.\n",
    "Then, add the metadata information from the 10<sup>th</sup> spreadsheet as columns in the combined `DataFrame`.\n",
    "Make sure that the final `DataFrame` has a unique index and all the `NaN` values have been replaced by the tag `unknown`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Class War in Titanic\n",
    "\n",
    "Use pandas to import the data file `Data/titanic.xls`. It contains data on all the passengers that travelled on the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(filename=DATA_FOLDER+'/titanic.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the following questions state clearly your assumptions and discuss your findings:\n",
    "1. Describe the *type* and the *value range* of each attribute. Indicate and transform the attributes that can be `Categorical`. \n",
    "2. Plot histograms for the *travel class*, *embarkation port*, *sex* and *age* attributes. For the latter one, use *discrete decade intervals*. \n",
    "3. Calculate the proportion of passengers by *cabin floor*. Present your results in a *pie chart*.\n",
    "4. For each *travel class*, calculate the proportion of the passengers that survived. Present your results in *pie charts*.\n",
    "5. Calculate the proportion of the passengers that survived by *travel class* and *sex*. Present your results in *a single histogram*.\n",
    "6. Create 2 equally populated *age categories* and calculate survival proportions by *age category*, *travel class* and *sex*. Present your results in a `DataFrame` with unique index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

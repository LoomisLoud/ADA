{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Task-1.-Compiling-Ebola-Data\"><span class=\"toc-item-num\">Task 1.&nbsp;&nbsp;</span>Compiling Ebola Data</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-2.-RNA-Sequences\"><span class=\"toc-item-num\">Task 2.&nbsp;&nbsp;</span>RNA Sequences</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-3.-Class-War-in-Titanic\"><span class=\"toc-item-num\">Task 3.&nbsp;&nbsp;</span>Class War in Titanic</a></div></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data' # Use the data folder provided in Tutorial 02 - Intro to Pandas.\n",
    "EBOLA = DATA_FOLDER + \"/ebola\"\n",
    "GUINEA = EBOLA + \"/guinea_data\"\n",
    "LIBERIA = EBOLA + \"/liberia_data\"\n",
    "SIERRA_LEONE = EBOLA + \"/sl_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Compiling Ebola Data\n",
    "\n",
    "The `DATA_FOLDER/ebola` folder contains summarized reports of Ebola cases from three countries (Guinea, Liberia and Sierra Leone) during the recent outbreak of the disease in West Africa. For each country, there are daily reports that contain various information about the outbreak in several cities in each country.\n",
    "\n",
    "Use pandas to import these data files into a single `Dataframe`.\n",
    "Using this `DataFrame`, calculate for *each country*, the *daily average* per year of *new cases* and *deaths*.\n",
    "Make sure you handle all the different expressions for *new cases* and *deaths* that are used in the reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Importing the data\n",
    "\n",
    "First of all, we will split the cleaning in three parts, one for each country, since the files were consistent for each country. Hence, we start by loading all of the data from each folder into three different DataFrames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# A few helper functions\n",
    "\n",
    "\"\"\"\n",
    "Returns a pandas dataframe from a folder full of \n",
    "csv files.\n",
    "\"\"\"\n",
    "def create_folder_data_frame(FOLDER):\n",
    "    list_ = []\n",
    "    for file_ in glob.glob(FOLDER + \"/*.csv\"):\n",
    "        df = pd.read_csv(file_, index_col=None)\n",
    "        list_.append(df)\n",
    "    return pd.concat(list_)\n",
    "\n",
    "\"\"\"\n",
    "Sets a new column \"Country\" that becomes part of a multi index\n",
    "afterwards, and returns the indexed frame.\n",
    "\"\"\"\n",
    "def index_and_country(data_frame, country):\n",
    "    data_frame[\"Country\"] = country\n",
    "    data_frame.set_index(['Date', 'Description', 'Country'], inplace=True)\n",
    "    return data_frame\n",
    "    \n",
    "\"\"\"\n",
    "We preprocess each Country one after the other and set their indices\n",
    "to a MultiIndex of Date, Description and Country, with each column\n",
    "mapped to one of these indices.\n",
    "\"\"\"\n",
    "def preprocess(FOLDER, name, columns=None):\n",
    "    frame = create_folder_data_frame(FOLDER)\n",
    "    if columns:\n",
    "        frame.rename(columns=columns, inplace=True)\n",
    "    frame.Date = pd.to_datetime(frame.Date)\n",
    "    frame = index_and_country(frame, name)\n",
    "    return frame\n",
    "    \n",
    "preprocessed_guinea = preprocess(GUINEA, \"Guinea\")\n",
    "\n",
    "liberia_column_mapping = {\"Variable\": \"Description\", \"National\": \"Totals\", 'Unnamed: 18': \"Unknown\"}\n",
    "preprocessed_liberia = preprocess(LIBERIA, \"Liberia\", liberia_column_mapping)\n",
    "\n",
    "sierra_column_mapping = {\"variable\": \"Description\", \"National\": \"Totals\", 'Unnamed: 18': \"Unknown\", \"date\": \"Date\"}\n",
    "preprocessed_sierra = preprocess(SIERRA_LEONE, \"Sierra Leone\", sierra_column_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Cleaning up\n",
    "\n",
    "Now that we have our three DataFrames, we need to merge them into a single one in order to query it to get the daily average deaths and cases. What we need to do in order to merge them, is to clean each DataFrame, and create a consistency inbetween columns after choosing which columns to use.\n",
    "\n",
    "After taking a look at the data, we decided to deliver the daily average of new cases and new deaths as a sum of the following categories: the suspected, probables, and confirmed cases and deaths, hence we only kept for each DataFrame the right columns. When the \"right\" columns are not perfectly defined, we explain which one we chose and why. The following set of columns are preselected after looking at the data, the other columns were either inconsistent or made no sense whatsoever.\n",
    "\n",
    "#### 1.2.1 Guinea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The columns that are of interest to us, mapped\n",
    "# to their centralized names for the final DataFrame\n",
    "interest = { 'New cases of suspects': 'new_suspected',\n",
    "        'New cases of probables': 'new_probable',\n",
    "        'New cases of confirmed': 'new_confirmed',\n",
    "        'Total deaths (confirmed + probables + suspects)': 'deaths',\n",
    "        'Total deaths of suspects': 'death_suspected',\n",
    "        'Total deaths of probables': 'death_probable',\n",
    "        'Total deaths of confirmed': 'death_confirmed' }\n",
    "\n",
    "    \n",
    "# We start by keeping only the interesting columns for the task\n",
    "interest_indices = preprocessed_guinea.index.get_level_values('Description').isin(interest.keys())\n",
    "guinea_df = preprocessed_guinea[interest_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now here is the first assumption we made regarding the data of Guinea, there are no missing values in the totals of deaths, but there are some NaN values in the New cases. We figured that of these new cases, NaN meant that there were either no data for the day, or that the data was not entered. It seems more plausible that people did not fill the data when there was no new cases, so we went with that explanation and changed all NaN values to 0. Also, since the number of cases and deaths can only be discrete we converted the dataframe to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guinea_df = guinea_df.fillna(0).astype(int)\n",
    "guinea_df = guinea_df.sort_index(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By verifying that the sum of cities and the total column are the same, we can see that there are some discrepencies. We then decided to remove the rows where the discrepencies are too high, namely 10% compared to the Totals column. Otherwise we keep the row, and we finally decided to keep mean of both columns, as they were quite similar, and it was impossible to split them apart and choose one. So the mean is the most obvious merging tool. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Keeping only the interesting columns, namely one for the Total\n",
    "# and one for the total of cities, to filter out unreliable data points\n",
    "guinea_df['Cities_total'] = guinea_df.sum(1) - guinea_df.Totals\n",
    "guinea_df = guinea_df[['Cities_total', 'Totals']]\n",
    "equality = sum(guinea_df['Cities_total'] == guinea_df['Totals']) == 0\n",
    "print(\"Does the sum of cities equal the Totals columm ? {}\".format(equality))\n",
    "\n",
    "# Now we want to remove the rows for which the total of cities \n",
    "# diverges from the Totals column of at least 10%\n",
    "guinea_df = guinea_df[np.abs(guinea_df.Cities_total - guinea_df.Totals) <= (0.1 * guinea_df.Totals)]\n",
    "guinea_df['Totals'] = guinea_df.mean(1)\n",
    "guinea_df = guinea_df.Totals\n",
    "\n",
    "# Converting the indices to columns, and readjusting the indices\n",
    "guinea_df = guinea_df.unstack('Description', fill_value=0)\n",
    "guinea_df.rename(columns=interest, inplace=True)\n",
    "\n",
    "display(HTML(guinea_df.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the total deaths, we can see that there is a row where we have missing data, we assumed here that the person forgot to write the measurements, hence we decided to fill the row with the mean of the previous and next measurements. That would simulate a linear increase and seems reasonable for one data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filling the row with the mean of the previous and next measurements\n",
    "# We also remove the cumulative sum, in order to get the daily data\n",
    "for c in guinea_df.columns:\n",
    "    if \"death_\" in c:\n",
    "        guinea_df[c].loc[('2014-09-26', 'Guinea')] = int((guinea_df[c].loc[('2014-09-24', 'Guinea')] + guinea_df[c].loc[('2014-09-30', 'Guinea')]) / 2)\n",
    "        guinea_df[c] = guinea_df[c] - guinea_df[c][0]\n",
    "        guinea_df[c][1:] = guinea_df[c][1:].copy().as_matrix() - guinea_df[c][:-1].copy().as_matrix()\n",
    "        \n",
    "# And finally, since the data can get negative because of the previous\n",
    "# computations we made, we can set them back to 0\n",
    "guinea_df[guinea_df < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can take a look at the sum of all 3 categories into one. But first, we need to choose how to process the fact that we can pick either from the deaths column or the sum of the three other categories of deaths. Let's take a look at the difference between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "guinea_df['new_cases'] = guinea_df[['new_suspected', 'new_confirmed', 'new_probable']].sum(axis=1)\n",
    "guinea_df['deaths_summed'] = guinea_df[['death_confirmed', 'death_probable', 'death_suspected']].sum(axis=1)\n",
    "# We reverse the cumulative sum on the deaths column to get a daily value\n",
    "guinea_df['deaths'] = guinea_df['deaths'] - guinea_df['deaths'][0]\n",
    "guinea_df['deaths'][1:] = guinea_df['deaths'][1:].copy().as_matrix() - guinea_df['deaths'][:-1].copy().as_matrix()\n",
    "\n",
    "display(HTML(guinea_df[['deaths', 'deaths_summed']].to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at the column deaths and the column death_summed, we can clearly see that they are about the same, besides a few discrepencies and two or three clearly wrong values. Hence, we decided to only retain the deaths_summed column that seemed more consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We now have a clean DataFrame to work with:\n",
    "guinea_df = guinea_df[['new_cases', 'deaths_summed']]\n",
    "guinea_df.rename(columns={'deaths_summed':'deaths'}, inplace=True)\n",
    "\n",
    "display(HTML(guinea_df.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Sierra Leone\n",
    "\n",
    "Now for Sierra Leone, most of our assumptions still hold, so we will explain less of our choices, and quickly explain through comments. If there is something new, we will explain it more thoroughly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setting all values to integer and replacing all NaNs by 0\n",
    "preprocessed_sierra = preprocessed_sierra.apply(pd.to_numeric,errors='coerce')\n",
    "preprocessed_sierra = preprocessed_sierra.fillna(0).astype(int)\n",
    "\n",
    "# We wanted to check if the 'Police traning School' and 'Police training School' were the same\n",
    "# As the sum of 'Police traning School' equals 0, we decided to drop this one\n",
    "# which must have been a typo\n",
    "print('Sum for Police traning: ', preprocessed_sierra['Police traning School'].sum())\n",
    "print('Sum for Police training: ', preprocessed_sierra['Police training School'].sum())\n",
    "preprocessed_sierra.drop('Police traning School', axis =1, inplace=True)\n",
    "\n",
    "\n",
    "# Just like before, keeping only the interesting descriptions\n",
    "interest = ['death_suspected',\n",
    "               'new_probable',\n",
    "               'new_suspected',\n",
    "               'death_confirmed',\n",
    "               'new_confirmed',\n",
    "               'death_probable']\n",
    "indices_interest = preprocessed_sierra.index.get_level_values('Description').isin(interest)\n",
    "preprocessed_sierra = preprocessed_sierra[indices_interest]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we did the columns a bit differently, same as before, we compute the sum of cities and compare it to the Totals column. We then remove outliers by computing the difference between the maximum of both columns and the mean. This is a precise metric to decide wether a point is an outlier or not, it is quite robust against the main problem: columns containing 0 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_sierra['Cities_total'] = preprocessed_sierra.sum(axis=1) - preprocessed_sierra['Totals']\n",
    "preprocessed_sierra['Mean'] = (preprocessed_sierra['Totals'] + preprocessed_sierra['Cities_total']) / 2\n",
    "max_of_both = preprocessed_sierra[['Cities_total', 'Totals']].max(1)\n",
    "preprocessed_sierra = preprocessed_sierra[np.abs(max_of_both - preprocessed_sierra.Mean) <= (0.1 * preprocessed_sierra.Mean)]\n",
    "\n",
    "# We remove rows with 0 in the death columns\n",
    "# Indeed these are cumulative columns and so a 0 makes no sense.\n",
    "# Before we changed one row, but here there are too many rows to do this.\n",
    "sierra = preprocessed_sierra['Mean'].unstack('Description', fill_value=0)\n",
    "sierra = sierra[(sierra['death_suspected'] != 0) & (sierra['death_probable'] != 0) & (sierra['death_confirmed'] != 0) ]\n",
    "\n",
    "#The data give us only the cumulated total for the deaths. So we computed the dayly numbers of deaths\n",
    "deaths = ['death_suspected', 'death_probable', 'death_confirmed']\n",
    "for c in sierra.columns:\n",
    "    if c in deaths:\n",
    "        sierra[c] = sierra[c] - sierra[c][0]\n",
    "        sierra[c][1:] = sierra[c][1:].copy().as_matrix() - sierra[c][:-1].copy().as_matrix()\n",
    "\n",
    "#Set the minimum value to 0    \n",
    "sierra = sierra.clip(lower=0)\n",
    "sierra['deaths'] = sierra['death_suspected'] + sierra['death_probable'] + sierra['death_confirmed']\n",
    "sierra['new_cases'] = sierra['new_confirmed'] + sierra['new_probable'] +sierra['new_suspected']\n",
    "sierra = sierra[['deaths', 'new_cases']]\n",
    "display(HTML(sierra.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 Liberia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Merging and answering the questions\n",
    "\n",
    "Here is the final DataFrame, of all deaths and new_cases sorted by date and country. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola_df = pd.concat([guinea_df, sierra]).sort_index(0)\n",
    "display(HTML(ebola_df.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Liberia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'Total suspected cases’, 'Total confirmed cases', 'Total probable cases'  (octobre et ½ decembre NaN)\n",
    "- ‘Cumulative confirmed, probable and suspected cases’ seulement 33 lignes (octobre novembre decembre présent)\n",
    "- 'Cumulative (confirmed + probable + suspected)' : une seule date avec diplication d’index … (2014-10-04)\n",
    "- 'Cumulative (confirmed + probable + suspects)' : 11 dates (octobre)\n",
    "-  'Newly reported deaths' : toutes les dates mais : 12 NaN <br>\n",
    "{Timestamp('2014-09-20 00:00:00'), Timestamp('2014-11-28 00:00:00'), Timestamp('2014-11-30 00:00:00'), Timestamp('2014-12-01 00:00:00'), Timestamp('2014-12-02 00:00:00'), Timestamp('2014-12-03 00:00:00'), Timestamp('2014-12-04 00:00:00'), Timestamp('2014-12-05 00:00:00'), Timestamp('2014-12-06 00:00:00'), Timestamp('2014-12-07 00:00:00'), Timestamp('2014-12-08 00:00:00'), Timestamp('2014-12-09 00:00:00')}\n",
    "- 'Total death/s in confirmed, probable, suspected cases' : 76 lignes présentent (mais index en double pour le 10-04 …)  et deux dates NaN <br>\n",
    "{Timestamp('2014-09-20 00:00:00'), Timestamp('2014-10-11 00:00:00')}\n",
    "\n",
    "\n",
    "\n",
    "NaN Values des 6 descriptions de bases:\n",
    "- New Suspected/Probable : 3 jours (alors que parfois il y a des 0)\n",
    "- New Confirmed : tout le mois de Novembre ......\n",
    "- Total death/s in confirmed cases /probable/suspected : octobre/novembre/decembre ... (3 mois sur 6)\n",
    "- Newly reported deaths : 3 jours + decembre\n",
    "- Total death/s in confirmed, probable, suspected cases : 4 jours + novembre/decembre\n",
    "- Total confirmed cases : octobre, 1 jour en novembre, mi decembre\n",
    "We print the daily average per month of deaths and new cases of ebola by country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les colonnes qui nous intérèssent le plus. Ce sont les plus complètent mais on va continuer à les\n",
    "# analyser en faisant la df pour afiner les données.(voir markdown pour ecplication) \n",
    "interest_liberia = { 'New Case/s (Suspected)': 'new_suspected', \n",
    "        'New Case/s (Probable)': 'new_probable', \n",
    "        'New case/s (confirmed)': 'new_confirmed', \n",
    "        'Total death/s in suspected cases': 'death_suspected', \n",
    "        'Total death/s in probable cases': 'death_probable', \n",
    "        'Total death/s in confirmed cases': 'death_confirmed',\n",
    "        'Total death/s in confirmed, probable, suspected cases': 'total_death'}\n",
    "\n",
    "# We start by keeping only the interesting columns for the task\n",
    "interest_liberia_indices = preprocessed_liberia.index.get_level_values('Description').isin(interest_liberia.keys())\n",
    "liberia_df = preprocessed_liberia[interest_liberia_indices]\n",
    "\n",
    "# Replacing all NaN values by 0 since we assumed that no value\n",
    "# meant no new cases/new deaths on this day\n",
    "# Transforming every dtype to integer\n",
    "# Sorting on the date\n",
    "liberia_df = liberia_df.fillna(0).astype(int).sort_index(0)\n",
    "\n",
    "# Keeping only the interesting columns, namely one for the Total\n",
    "# and one for the total of cities, to filter out unreliable data points\n",
    "liberia_df['Cities_total'] = liberia_df.sum(1) - liberia_df.Totals\n",
    "liberia_df = liberia_df[['Cities_total', 'Totals']]\n",
    "\n",
    "# Now we want to veriy the rows for which the total of cities \n",
    "# diverges from the Totals column of at least 10%\n",
    "liberia_df_limit = liberia_df[np.abs(liberia_df.Cities_total - liberia_df.Totals) > (0.1 * liberia_df.Totals)]\n",
    "\n",
    "# Then we decide to remove the ones with cumulative (total) description,\n",
    "# because the values are bigger thus the 10% divergences are more significant\n",
    "liberia_df_total = liberia_df_limit.xs('Total death/s in confirmed, probable, suspected cases', level='Description')\n",
    "total_date = liberia_df_total.index.get_level_values(0)\n",
    "\n",
    "# We remove the rows with one zero and 10% of divergernce\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!\n",
    "liberia_df_zero = liberia_df_limit[(liberia_df_limit.values == 0)]\n",
    "zero_date = liberia_df_zero.index.get_level_values(0)\n",
    "\n",
    "# Thus we drop these rows according to their date index\n",
    "to_drop = total_date.append(zero_date).strftime('%Y-%m-%d')\n",
    "liberia_df.drop(to_drop, level=0, inplace=True)\n",
    "\n",
    "# We compute the mean between the total and the total of cities\n",
    "# and we keep this final value. (!!!!!!!!!!!!!!)\n",
    "liberia_df['Mean'] = liberia_df.mean(1)\n",
    "liberia_df = liberia_df.Mean\n",
    "\n",
    "# Converting the indices to columns, and readjusting the indices\n",
    "liberia_df = liberia_df.unstack('Description', fill_value=0)\n",
    "liberia_df.columns.rename('', inplace=True)\n",
    "\n",
    "# changing the names of all indices to match other countries dataframes\n",
    "liberia_df = liberia_df.rename(columns=interest_liberia)\n",
    "\n",
    "# We sum the 'suspected, probable and confirmed' columns in order to get\n",
    "# a more general and complete dataframe.\n",
    "liberia_df['total_death_sum'] = liberia_df[['death_suspected','death_probable','death_confirmed']].sum(1)\n",
    "liberia_df['new_cases_sum'] = liberia_df[['new_probable','new_suspected','new_confirmed']].sum(1)\n",
    "\n",
    "# Moreover it allows us to compare the total death sum with the one present directly in the data\n",
    "liberia_df_diff = liberia_df[liberia_df['total_death_sum'] != liberia_df['total_death']]\n",
    "# ~~~~~~~~~~~~~~~~~~~~AFFICHER en HTML~~~~~~~~~~~~~~~~~~~~~\n",
    "liberia_df_diff[['total_death','total_death_sum']]\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#Markdown pour expliquer pour on garde 'Total death/s in confirmed, probable, suspected cases' à la place de la somme\n",
    "\n",
    "# We keep our final columns\n",
    "liberia_df = liberia_df[['total_death', 'new_cases_sum']]\n",
    "\n",
    "# he data give us only the cumulated total for the deaths. So we computed the dayly numbers of deaths\n",
    "liberia_df['total_death'] = liberia_df['total_death'] - liberia_df['total_death'][0]\n",
    "liberia_df['total_death'][1:] = liberia_df['total_death'][1:].copy().as_matrix() - liberia_df['total_death'][:-1].copy().as_matrix()\n",
    "\n",
    "# Moreover we have noticed that the last 6 rows of the new cases seem to be cumulative instead of daily\n",
    "# that is why we process in the same way for these dates\n",
    "liberia_df['new_cases_sum'][-6:] = liberia_df['new_cases_sum'][-6:] - liberia_df['new_cases_sum'][-6:][0]\n",
    "liberia_df['new_cases_sum'][-6:][1:] = liberia_df['new_cases_sum'][-6:][1:].copy().as_matrix() - liberia_df['new_cases_sum'][-6:][:-1].copy().as_matrix()\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~ AFFICHER ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "print(liberia_df['total_death'].value_counts().sort_index())\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#Markdown pour expliquer qu'on a eu des valeurs negatives qui sont apparus\n",
    "# aux valeurs qui ne faisaient pas augmenter le total (fausse)\n",
    "# et aussi il y a des extrems (les 4 valeurs au dessus de 1700)\n",
    "#On met tout à zero\n",
    "\n",
    "liberia_df[((liberia_df < 0) | (liberia_df > 1700))] = 0\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~AFFICHER LE FINAL~~~~~~~~~~~~~~~~~~~~~~\n",
    "liberia_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guinea: Total new cases registered so far\n",
    "        ",
    "print(\"Here are the daily averages by month for each country:\")\n",
    "grouped_df = ebola_df.groupby([ebola_df.index.get_level_values('Date').month, \n",
    "                             ebola_df.index.get_level_values('Country')])\n",
    "print(grouped_df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. RNA Sequences\n",
    "\n",
    "In the `DATA_FOLDER/microbiome` subdirectory, there are 9 spreadsheets of microbiome data that was acquired from high-throughput RNA sequencing procedures, along with a 10<sup>th</sup> file that describes the content of each. \n",
    "\n",
    "Use pandas to import the first 9 spreadsheets into a single `DataFrame`.\n",
    "Then, add the metadata information from the 10<sup>th</sup> spreadsheet as columns in the combined `DataFrame`.\n",
    "Make sure that the final `DataFrame` has a unique index and all the `NaN` values have been replaced by the tag `unknown`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "microbiome = '/microbiome'\n",
    "def create_folder_data_frame(FOLDER):\n",
    "    list_ = []\n",
    "    for file_ in glob.glob(FOLDER + \"\\*.xls\"):\n",
    "        if file_ != FOLDER + '\\metadata.xls':\n",
    "            print(file_)\n",
    "            df = pd.read_excel(file_, index_col=None)\n",
    "            list_.append(df)\n",
    "    return pd.concat(list_)\n",
    "create_folder_data_frame(DATA_FOLDER+microbiome)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Class War in Titanic\n",
    "\n",
    "Use pandas to import the data file `Data/titanic.xls`. It contains data on all the passengers that travelled on the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(filename=DATA_FOLDER+'/titanic.html')\n",
    "#sierra = sierra.groupby([sierra.index.get_level_values('Date').month,sierra.index.get_level_values('Country')]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the following questions state clearly your assumptions and discuss your findings:\n",
    "1. Describe the *type* and the *value range* of each attribute. Indicate and transform the attributes that can be `Categorical`. \n",
    "2. Plot histograms for the *travel class*, *embarkation port*, *sex* and *age* attributes. For the latter one, use *discrete decade intervals*. \n",
    "3. Calculate the proportion of passengers by *cabin floor*. Present your results in a *pie chart*.\n",
    "4. For each *travel class*, calculate the proportion of the passengers that survived. Present your results in *pie charts*.\n",
    "5. Calculate the proportion of the passengers that survived by *travel class* and *sex*. Present your results in *a single histogram*.\n",
    "6. Create 2 equally populated *age categories* and calculate survival proportions by *age category*, *travel class* and *sex*. Present your results in a `DataFrame` with unique index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your answer here\n",
    "titanic_xls = pd.read_excel(DATA_FOLDER +'/titanic.xls')\n",
    "titanic_xls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}



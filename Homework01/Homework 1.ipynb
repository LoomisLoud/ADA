{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Task-1.-Compiling-Ebola-Data\"><span class=\"toc-item-num\">Task 1.&nbsp;&nbsp;</span>Compiling Ebola Data</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-2.-RNA-Sequences\"><span class=\"toc-item-num\">Task 2.&nbsp;&nbsp;</span>RNA Sequences</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-3.-Class-War-in-Titanic\"><span class=\"toc-item-num\">Task 3.&nbsp;&nbsp;</span>Class War in Titanic</a></div></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data' # Use the data folder provided in Tutorial 02 - Intro to Pandas.\n",
    "EBOLA = DATA_FOLDER + \"/ebola\"\n",
    "GUINEA = EBOLA + \"/guinea_data\"\n",
    "LIBERIA = EBOLA + \"/liberia_data\"\n",
    "SIERRA_LEONE = EBOLA + \"/sl_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Compiling Ebola Data\n",
    "\n",
    "The `DATA_FOLDER/ebola` folder contains summarized reports of Ebola cases from three countries (Guinea, Liberia and Sierra Leone) during the recent outbreak of the disease in West Africa. For each country, there are daily reports that contain various information about the outbreak in several cities in each country.\n",
    "\n",
    "Use pandas to import these data files into a single `Dataframe`.\n",
    "Using this `DataFrame`, calculate for *each country*, the *daily average* per year of *new cases* and *deaths*.\n",
    "Make sure you handle all the different expressions for *new cases* and *deaths* that are used in the reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### sierra_descriptions = set([b for a,b,c, in list(preprocessed_sierra.index.values)])\n",
    "print(\"Sierra: {}\\n\".format(sierra_descriptions))\n",
    "\n",
    "guinea_descriptions = set([b for a,b,c, in list(preprocessed_guinea.index.values)])\n",
    "print(\"Guinea: {}\\n\".format(guinea_descriptions))\n",
    "\n",
    "liberia_descriptions = set([b for a,b,c, in list(preprocessed_liberia.index.values)])\n",
    "print(\"Liberia: {}\\n\".format(liberia_descriptions))\n",
    "#sierra[~sierra['34 Military Hospital'].isnull()]\n",
    "#preprocessed_sierra.iloc[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Importing the data\n",
    "\n",
    "First of all, we will split the cleaning in three parts, one for each country, since the files were consistent for each country. Hence, we start by loading all of the data from each folder into three different DataFrames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# A few helper functions\n",
    "\n",
    "\"\"\"\n",
    "Returns a pandas dataframe from a folder full of \n",
    "csv files.\n",
    "\"\"\"\n",
    "def create_folder_data_frame(FOLDER):\n",
    "    list_ = []\n",
    "    for file_ in glob.glob(FOLDER + \"/*.csv\"):\n",
    "        df = pd.read_csv(file_, index_col=None)\n",
    "        list_.append(df)\n",
    "    return pd.concat(list_)\n",
    "\n",
    "\"\"\"\n",
    "Sets a new column \"Country\" that becomes part of a multi index\n",
    "afterwards, and returns the indexed frame.\n",
    "\"\"\"\n",
    "def index_and_country(data_frame, country):\n",
    "    data_frame[\"Country\"] = country\n",
    "    data_frame.set_index(['Date', 'Description', 'Country'], inplace=True)\n",
    "    return data_frame\n",
    "    \n",
    "\"\"\"\n",
    "We preprocess each Country one after the other and set their indices\n",
    "to a MultiIndex of Date, Description and Country, with each column\n",
    "mapped to one of these indices.\n",
    "\"\"\"\n",
    "def preprocess(FOLDER, name, columns=None):\n",
    "    frame = create_folder_data_frame(FOLDER)\n",
    "    if columns:\n",
    "        frame.rename(columns=columns, inplace=True)\n",
    "    frame.Date = pd.to_datetime(frame.Date)\n",
    "    frame = index_and_country(frame, name)\n",
    "    return frame\n",
    "    \n",
    "preprocessed_guinea = preprocess(GUINEA, \"Guinea\")\n",
    "\n",
    "liberia_column_mapping = {\"Variable\": \"Description\", \"National\": \"Totals\", 'Unnamed: 18': \"Unknown\"}\n",
    "preprocessed_liberia = preprocess(LIBERIA, \"Liberia\", liberia_column_mapping)\n",
    "\n",
    "sierra_column_mapping = {\"variable\": \"Description\", \"National\": \"Totals\", 'Unnamed: 18': \"Unknown\", \"date\": \"Date\"}\n",
    "preprocessed_sierra = preprocess(SIERRA_LEONE, \"Sierra Leone\", sierra_column_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropped because: Only one date given, not related to the question\n",
    "\n",
    "Decided to drop anything but the columns in our interest after checking them out, they were quite consistent with the others (taking New cases of suspects vs taking Total cases of suspects gives roughly the same data)\n",
    "\n",
    "Dropping all of the rows in which the sum of all cities diverges from the total column of at least 10%, which is a good margin to decide whether or not a data point is good or not. In fact in the case of an epidemic, one of these measurements is highly improbably going to skyrocket on a day, and go back to normal on the other.\n",
    "\n",
    "Of course the sum of cities sometimes diverges from the \"total\" column, but we simply assumed that we are missing some cities, and this is why we chose to consider the column \"Totals\" as the right column from which to pick the number of persons\n",
    "\n",
    "Considering NaN as 0\n",
    "\n",
    "Assuming that there are no .5 people, we can transform everything to integers\n",
    "\n",
    "Cases: \n",
    "    'Total new cases registered so far'\n",
    "    'Total cases of suspects'\n",
    "    'Total cases of probables'\n",
    "    'Total cases of confirmed'\n",
    "    'New cases of suspects'\n",
    "    'New cases of probables'\n",
    "    'New cases of confirmed'\n",
    "    'Cumulative (confirmed + probable + suspects)'\n",
    "    \n",
    "Deaths:\n",
    "    'Total deaths of suspects'\n",
    "    'Total deaths of probables'\n",
    "    'Total deaths of confirmed'\n",
    "    'Total deaths (confirmed + probables + suspects)'\n",
    "    'New deaths registered'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Cleaning up\n",
    "\n",
    "Now that we have our three DataFrames, we need to merge them into a single one in order to query it to get the daily average deaths and cases. What we need to do in order to merge them, is to clean each DataFrame, and create a consistency inbetween columns after choosing which columns to use.\n",
    "\n",
    "After taking a look at the data, we decided to deliver the daily average of new cases and new deaths in three categories, the suspected, probables, and confirmed cases and deaths, hence we only kept for each DataFrame the right columns.\n",
    "\n",
    "#### 1.2.1 Guinea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#preprocessed_sierra = preprocess_sierra(SIERRA_LEONE)\n",
    "\n",
    "#Set all values to integer and replace NaN by 0.\n",
    "preprocessed_sierra = preprocessed_sierra.apply(pd.to_numeric,errors='coerce')\n",
    "preprocessed_sierra = preprocessed_sierra.fillna(0.0).astype(int)\n",
    "\n",
    "#Keep descriptions with interest for us\n",
    "description = ['death_suspected', 'new_probable', 'new_suspected', 'death_confirmed', 'new_confirmed', 'death_probable']\n",
    "ix=preprocessed_sierra.index.get_level_values('Description').isin(description)\n",
    "preprocessed_sierra = preprocessed_sierra[ix]\n",
    "\n",
    "#Create new DataFrame with descriptions as columns\n",
    "sierra = pd.DataFrame()\n",
    "for cat in description:\n",
    "    sierra[cat] = preprocessed_sierra.xs((cat, 'Sierra Leone'), level=('Description', 'Country'))['Totals'].tolist()\n",
    "\n",
    "#The data give us only the cumulated total for the deaths. So we computed the dayly numbers of deaths\n",
    "deaths = ['death_suspected', 'death_probable', 'death_confirmed']\n",
    "for c in sierra.columns:\n",
    "    if c in deaths:\n",
    "        sierra[c] = sierra[c] - sierra[c][0]\n",
    "        sierra[c][1:] = sierra[c][1:].copy().as_matrix() - sierra[c][:-1].copy().as_matrix()\n",
    "\n",
    "#Set the minimum value to 0    \n",
    "sierra = sierra.clip(lower=0)\n",
    "\n",
    "#Set the country and the date as index\n",
    "sierra['Country'] = 'Sierra Leone'\n",
    "date = sorted(list(set(preprocessed_sierra.index.get_level_values('Date'))))\n",
    "sierra['Date'] = date\n",
    "sierra.set_index(['Date', 'Country'],inplace=True)\n",
    "sierra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Compute the mean by month and country\n",
    "#sierra = sierra.groupby([sierra.index.get_level_values('Date').month,sierra.index.get_level_values('Country')]).mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The columns that are to interest to us, mapped\n",
    "# to their centralized names for the final DataFrame\n",
    "interest = { 'New cases of suspects': 'new_suspected',\n",
    "        'New cases of probables': 'new_probable',\n",
    "        'New cases of confirmed': 'new_confirmed',\n",
    "        'Total deaths of suspects': 'death_suspected',\n",
    "        'Total deaths of probables': 'death_probable',\n",
    "        'Total deaths of confirmed': 'death_confirmed' }\n",
    "    \n",
    "# We start by keeping only the interesting columns for the task\n",
    "interest_indices = preprocessed_guinea.index.get_level_values('Description').isin(interest.keys())\n",
    "guinea_df = preprocessed_guinea[interest_indices]\n",
    "\n",
    "# Replacing all NaN values by 0 since we assumed that no value\n",
    "# meant no new cases/new deaths on this day\n",
    "# Transforming every dtype to integer\n",
    "guinea_df = guinea_df.fillna(0).astype(int)\n",
    "\n",
    "# Sorting on the date\n",
    "guinea_df = guinea_df.sort_index(0)\n",
    "\n",
    "# Keeping only the interesting columns, namely one for the Total\n",
    "# and one for the total of cities, to filter out unreliable data points\n",
    "guinea_df['Cities_total'] = guinea_df.sum(1) - guinea_df.Totals\n",
    "guinea_df = guinea_df[['Cities_total', 'Totals']]\n",
    "print(guinea_df.columns)\n",
    "\n",
    "# Now we want to remove the rows for which the total of cities \n",
    "# diverges from the Totals column of at least 10%\n",
    "guinea_df = guinea_df[np.abs(guinea_df.Cities_total - guinea_df.Totals) <= (0.1 * guinea_df.Totals)]\n",
    "guinea_df = guinea_df.Totals\n",
    "\n",
    "# Converting the indices to columns, and readjusting the indices\n",
    "guinea_df = guinea_df.unstack('Description', fill_value=0)\n",
    "guinea_df.columns.rename('', inplace=True)\n",
    "\n",
    "# We saw the missing values in the Total columns, let's fill them by\n",
    "# the mean of the previous and next columns. Considering that there is\n",
    "# only one row with such a problem, we directly do it on the row\n",
    "# We also remove the cumulative sum, in order to get the daily data\n",
    "for c in guinea_df.columns:\n",
    "    if \"Total\" in c:\n",
    "        guinea_df[c].loc[('2014-09-26', 'Guinea')] = int((guinea_df[c].loc[('2014-09-24', 'Guinea')] + guinea_df[c].loc[('2014-09-30', 'Guinea')]) / 2)\n",
    "        guinea_df[c] = guinea_df[c] - guinea_df[c][0]\n",
    "        guinea_df[c][1:] = guinea_df[c][1:].copy().as_matrix() - guinea_df[c][:-1].copy().as_matrix()\n",
    "        \n",
    "# And finally, since the data can get negative because of the previous\n",
    "# computations we made, we can set them back to 0\n",
    "guinea_df[guinea_df < 0] = 0\n",
    "\n",
    "# We finalize by changing the names of all indices to match other countries dataframes\n",
    "guinea_df = guinea_df.rename(columns=interest)\n",
    "\n",
    "# We are done now, and we can merge the frames\n",
    "display(HTML(guinea_df.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now that we have a clean DataFrame to work with, we need to recreate the daily deaths from the total deaths in order to do so, we decided to set the first death of the dates to 0, in order to be able to compute the difference day by day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. RNA Sequences\n",
    "\n",
    "In the `DATA_FOLDER/microbiome` subdirectory, there are 9 spreadsheets of microbiome data that was acquired from high-throughput RNA sequencing procedures, along with a 10<sup>th</sup> file that describes the content of each. \n",
    "\n",
    "Use pandas to import the first 9 spreadsheets into a single `DataFrame`.\n",
    "Then, add the metadata information from the 10<sup>th</sup> spreadsheet as columns in the combined `DataFrame`.\n",
    "Make sure that the final `DataFrame` has a unique index and all the `NaN` values have been replaced by the tag `unknown`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Class War in Titanic\n",
    "\n",
    "Use pandas to import the data file `Data/titanic.xls`. It contains data on all the passengers that travelled on the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(filename=DATA_FOLDER+'/titanic.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the following questions state clearly your assumptions and discuss your findings:\n",
    "1. Describe the *type* and the *value range* of each attribute. Indicate and transform the attributes that can be `Categorical`. \n",
    "2. Plot histograms for the *travel class*, *embarkation port*, *sex* and *age* attributes. For the latter one, use *discrete decade intervals*. \n",
    "3. Calculate the proportion of passengers by *cabin floor*. Present your results in a *pie chart*.\n",
    "4. For each *travel class*, calculate the proportion of the passengers that survived. Present your results in *pie charts*.\n",
    "5. Calculate the proportion of the passengers that survived by *travel class* and *sex*. Present your results in *a single histogram*.\n",
    "6. Create 2 equally populated *age categories* and calculate survival proportions by *age category*, *travel class* and *sex*. Present your results in a `DataFrame` with unique index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
